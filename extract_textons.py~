import cv2
from sklearn.feature_extraction import image
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier
from collections import Counter
from scipy.spatial import distance
import texton_helpers

from scipy import spatial

# Idea: For an input image, calculate the histogram of clusters, i.e.
# how often does each texton from the dictionary (i.e. the example
# textons or texton cluster centers) occur.

# Afterwards, we do the same for a part of the 'map' and use that for
# a fast pre-localization algorithm

# To do this, we compare the query image with different views of the
# original image (for example with a sliding window)

# Ideally, it can also determine if we are currently between two
# clusters


def extract_textons(img, max_textons=None, texton_size=5):

    """
    This function extract textons from an image. If max_textons is set
    to None, all textons are extracted, otherwise random sampling is
    used.
    """

    patches = image.extract_patches_2d(img, 
                                       (texton_size, texton_size),
                                       max_textons)

    # Flatten 2D array
    patches = patches.reshape(-1, texton_size ** 2)

    return patches

    
def train_and_cluster_textons(textons, n_clusters=25):

    """
    Returns a classifier, learned from the orignal image, and the
    predictions for the classes of the input textons and the texton
    centers.

    """

    # TODO: Look at different parameters of n_init
    k_means = KMeans(n_clusters=n_clusters, n_init=10)

    # Predicted classes for the input textons
    predictions = k_means.fit_predict(np.float32(textons))

    # Texton class centers
    centers = k_means.cluster_centers_     

    return k_means, predictions, centers


def cluster_textons(textons, classifier):
    
    "This function clusters textons by means of a given classifier"

    classes = classifier.predict(np.float32(textons))
    return classes


def match_histograms(query_histogram, location_histogram):

    """
    Match query histogram with location histogram and return the
    distance. To do this, it needs a distance measurement.
    """
    
    # TODO: I could use the distance function as a parameter

    dist = np.linalg.norm(query_histogram - location_histogram)
    dist = spatial.distance.cosine(query_histogram, location_histogram)

    return dist
    

def display_textons(textons, input_is_1D=False):

    """
    This function displays the input textons 
    """

    if input_is_1D:
        
        l = len(textons[0])
        s = np.sqrt(l)
        w = int(s) 

        textons = textons.reshape(-1, w, w)

    plt.figure(1) # Create figure

    for i, texton in enumerate(textons):

        plt.subplot(np.ceil(s), np.ceil(s), i + 1) 
        plt.imshow(texton, 
                   cmap = cm.Greys_r, 
                   interpolation="nearest")
    
    plt.show()


def display_histogram(histogram):

    plt.bar(np.arange(len(histogram)), histogram)
    plt.show()



def img_to_texton_histogram(img, classifier, max_textons, n_clusters):

    print "Shape of image", img.shape

    # Extract all textons of the query image
    textons = extract_textons(img, max_textons)

    print "Length of textons", len(textons)

    # Get classes of textons of the query image
    clusters = cluster_textons(textons, classifier)

    # Get the frequency of each texton class of the query image
    histogram = np.bincount(clusters,
                            minlength=n_clusters) # minlength guarantees that missing clusters are set to 0 

    return histogram


def get_training_histograms(classifier, training_image, n_clusters=20):

    """
    Split the input image into patches and calculate the histogram for each patch
    """

    h, w = training_image.shape

    num_patches_h = 2
    num_patches_w = 3

    # window_offset = (h / 2, w / 2)
    window_offset = None
    
    patches = texton_helpers.sliding_window(training_image, (h / num_patches_h, w / num_patches_w), window_offset, True)

    print "Shape of training image", training_image.shape

    histograms = []

    # TODO: Could be done faster with map (or other higher-order functions)?!
    for patch in patches:
        
        print "Shape of patch", patch.shape

        # Extract textons for each patch
        patch_histogram = img_to_texton_histogram(patch, 
                                                  classifier, 
                                                  max_textons, 
                                                  n_clusters)
        print patch_histogram
        
        histograms.append(patch_histogram)

    print histograms

    return np.array(histograms), patches

def sliding_window_match(query_image,
                         location_image,
                         max_textons=None,
                         n_clusters=20,
                         SHOW_GRAPHS=True):
    
    """
    This function is the core function of this approach. It matches
    the query image with the location image at different patches. TO
    do this, it calculates the histogram of both images.
    """

    # I assume that I extract all textons from the training image and
    # get the histogram for the different patches off-line. This
    # should increase the speed of the algorithm.
    
    # Extract patches of the training image
    training_textons = extract_textons(location_image, max_textons)

    # Apply K-Means on the training image
    classifier, training_clusters, centers = train_and_cluster_textons(textons=training_textons, 
                                                                       n_clusters=n_clusters)

    # Display dictionary of textons
    if SHOW_GRAPHS:
        display_textons(np.int32(centers), input_is_1D=True)

    # Get histogram of the textons of patches of the training image
    
    training_histograms, patches = get_training_histograms(classifier, training_image, n_clusters)

    query_histogram = img_to_texton_histogram(query_image, classifier, max_textons, n_clusters)


    print training_histograms
    print query_histogram

    print query_histogram

    
    if SHOW_GRAPHS:
        display_histogram(query_histogram)
        
        for patch in patches:
            #cv2.imshow("Image patches", patch)
            print patch.shape
            plt.imshow(patch, 
                   cmap = cm.Greys_r)
            plt.show()


    
    # Perform classification by comparing the histogram of the
    # training and the query image (e.g. with nearest neighbors)
   
    # The output of the classification should be the position of the
    # query image in the localization image.
    
    # TODO: match_histogram should be a helper function for a function
    # that generates sliding windows and matches against them

    distances = []

    for training_histogram in training_histograms:
        dist = match_histograms(query_histogram, training_histogram)
        distances.append(dist)
        

    return distances, patches

        
if __name__ == "__main__":

    SHOW_GRAPHS = False

    # Path of the map (training image)
    training_image_path = "maze17.jpg"
    # training_image_path = "guy.jpg"
    #training_image_path =  "/home/pold87/Desktop/Bilder/P1080334.JPG"

    training_image = cv2.imread(training_image_path, 0)

    # Path of the query image (part of the map)
    query_image_path = "maze17topleft.png"
    query_image_path = "guynotidealmatch.png"
    query_image_path = "entirerightnotperfect.jpg"
    #query_image_path = "righttopnotperfect.jpg"
    #query_image_path = "topmiddlenotperfect.jpg"
    
    #query_image_path = "tlpic.jpg"
    query_image = cv2.imread(query_image_path, 0)

    # Max textons that are extracted from the input image
    max_textons = 2000
    max_textons = None

    # Number of clusters (i.e. texton cluster centers)
    n_clusters = 5
    
    distances, patches = sliding_window_match(query_image=query_image,
                                     location_image=training_image,
                                     max_textons=max_textons,
                                     n_clusters=n_clusters,
                                     SHOW_GRAPHS=False)

    print distances

    patch_pos = np.argmin(distances)
    patch_all_pos = np.argsort(distances)

    print "Best match", patch_pos
    print "All matches (best matches first)", patch_all_pos
    
    plt.imshow(patches[patch_pos], 'Greys')
    plt.show()
    
    #display_textons(patches)
