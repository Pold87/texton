#load_histograms

#use_xgboost
#use_dipoles

[textons]

# Size of texton dictionary
num_textons = 33

# Maximum amount of textons per image
max_textons = 1300

# Size of the textons
texton_size = 5


[regression]

# Use weights for samples (as confidence)
#sample_weight

# Perform tfidf
# tfidf

# Perform standarization
#standardize

# Standardize channel 2 and 3 by dividing them by channel 1
#color_standardize

# Use local standardization
# local_standardize

# Use CLAHE histogram standardization
#histogram_standardize

# Use separate classifiers for x and y
do_separate

# Path of SIFT ground truth file
#ground_truth_labeler = sift_targets.csv
ground_truth_labeler = sift_targets_ortho.csv

[visualization]

mode = 0
mymap = ../draug/img/bestnewmat.png
use_normal
#filter
dev = 0
show_histogram

[images]

# Number of channels (1: grayscale, 3: color)
channels = 1

# Use picture enhanced by draug (folder)
# use_draug_folder

# The amount of draug pictures to use
num_draug_pics = 1560
#num_draug_pics = 100

# The amount of valid pictures to use
num_valid_pics = 49

# Filenumber of the first valid picture
start_valid = 0

# The amount of test images to use
num_test_pics = 40

# Path to draug directory
# dir = imgs/
dir = /home/pold/paparazzi/video/
#dir = ../draug/genimgs/

# Path to test images
# Laptop
#test_imgs_path = /home/pold87/Documents/Internship/orthomap/imgs/

# PC
test_imgs_path = /home/pold/Documents/orthomap/tux/

# Discard the first pictures (offset)
start_pic_num = 0

# Show graphs of textons
# show_graphs

# Test on trainset (calculate training error)
# test_on_trainset

# Test on testset (calculate error)
# test_on_testset

# Test on validset (calculate valid error)
# test_on_validset

# Check if deprecated
# Path to the predictions of extract_textons_draug.py
predictions = predictions.npy
