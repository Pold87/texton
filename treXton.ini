#load_histograms

[textons]

# Size of texton dictionary
num_textons = 12

# Maximum amount of textons per image
max_textons = 1300

# Size of the textons
texton_size = 10


[regression]

# Perform tfidf
tfidf

# Perform standarization
#standardize

# Standardize channel 2 and 3 by dividing them by channel 1
#color_standardize

# Use local standardization
local_standardize

# Use CLAHE histogram standardization
#histogram_standardize

# Use separate classifiers for x and y
do_separate

# Path of SIFT ground truth file
#ground_truth_labeler = sift_targets.csv
ground_truth_labeler = sift_targets.csv

[visualization]

mode = 0
mymap = ../draug/img/bestnewmat.png
use_normal
#filter
dev = 1

[images]

# Number of channels (1: grayscale, 3: color)
channels = 3

# Use picture enhanced by draug (folder)
# use_draug_folder

# The amount of draug pictures to use
num_draug_pics = 1560

# The amount of valid pictures to use
num_valid_pics = 49

# Filenumber of the first valid picture
start_valid = 0

# The amount of test images to use
num_test_pics = 40

# Path to draug directory
dir = imgs/
#dir = ../draug/genimgs/

# Path to test images
test_imgs_path = /home/pold87/Documents/Internship/orthomap/imgs/

# Discard the first pictures (offset)
start_pic_num = 0

# Show graphs of textons
# show_graphs

# Test on trainset (calculate training error)
# test_on_trainset

# Test on testset (calculate error)
# test_on_testset

# Test on validset (calculate valid error)
# test_on_validset

# Check if deprecated
# Path to the predictions of extract_textons_draug.py
predictions = predictions.npy
